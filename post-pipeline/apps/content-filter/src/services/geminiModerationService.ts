import {
  GenerateContentParameters,
  GoogleGenAI,
  HarmBlockThreshold,
  HarmCategory,
} from '@google/genai';
import Post from '../post.js';

export interface ModerationResult {
  isApproved: boolean;
  reason: string;
}

export class GeminiModerationService {
  private readonly client: GoogleGenAI;

  constructor(apiKey: string) {
    if (!apiKey) throw new Error('GEMINI_API_KEY missing');
    this.client = new GoogleGenAI({ apiKey });
  }

  async checkPost(post: Post): Promise<ModerationResult> {
    const moderationPrompt = `
      You are a strict content-moderation assistant for a user-generated content pipeline.
      Given the post text and a social platform name, decide whether the post is ACCEPTABLE under the following community guidelines for ${post.socialPlatform}. The guidelines prohibit content that is:
      - Spam.

      Return **ONLY** JSON with these keys:
      - isApproved — true or false
      - reason — a short sentence (English) explaining the decision.
    `.trim();
    const fullPrompt = `${moderationPrompt}\n\nPost Text: "${post.text}"\nSocial Platform: "${post.socialPlatform}"`;

    const mediaParts =
      post.mediaFiles?.map((file) => ({
        inlineData: {
          mimeType: file.mimetype,
          data: file.buffer.toString('base64'),
        },
      })) ?? [];

    const requestParameters: GenerateContentParameters = {
      model: 'gemini-2.5-pro',
      contents: [{ role: 'user', parts: [{ text: fullPrompt }, ...mediaParts] }],
      config: {
        safetySettings: [
          {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
        ],

        responseMimeType: 'application/json',
        responseJsonSchema: {
          isApproved: Boolean,
          reason: String,
        },
      },
    };

    try {
      const response = await this.client.models.generateContent(requestParameters);

      // 1. First, check for a block from Gemini's built-in safety filters.
      const blockReason = response.promptFeedback?.blockReason;
      if (blockReason) {
        return {
          isApproved: false,
          reason: `Blocked by safety settings: ${blockReason}.`,
        };
      }

      // 2. If not blocked, extract the generated text.
      const generatedText = response.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!generatedText) {
        return {
          isApproved: false,
          reason: 'No content generated by the model.',
        };
      }
      const cleanedText = generatedText.replace(/```json|```/g, '').trim();

      // 3. Now, parse the JSON string from the generated text.
      try {
        const result: ModerationResult = JSON.parse(cleanedText);
        return result;
      } catch (parseError) {
        console.error('Failed to parse JSON response from model:', parseError);
        return {
          isApproved: false,
          reason: "Failed to parse model's moderation output as JSON.",
        };
      }
    } catch (err) {
      console.error('Gemini error', err);
      return {
        isApproved: false,
        reason: 'Gemini moderation failed.',
      };
    }
  }
}
