import {
  GoogleGenAI,
  HarmBlockThreshold,
  HarmCategory,
  GenerateContentParameters,
} from "@google/genai";
import Post from "../post.js";

export interface ModerationResult {
  isApproved: boolean;
  reason: string;
}

export class GeminiModerationService {
  private readonly client: GoogleGenAI;

  constructor(apiKey: string) {
    if (!apiKey) throw new Error("GEMINI_API_KEY missing");
    this.client = new GoogleGenAI({ apiKey });
  }

  async checkText(post: Post): Promise<ModerationResult> {
    const moderationPrompt = `
      You are a strict content-moderation assistant for a user-generated content pipeline.
      Given the post text and a social platform name, decide whether the post is ACCEPTABLE under the following community guidelines for ${post.socialPlatform}. The guidelines prohibit content that is:
      - Spam, deceptive, or misleading.
      - Promoting specific products or services without proper tags (e.g., #ad).

      Return **ONLY** JSON with these keys:
      - isApproved — true or false
      - reason — a short sentence (English) explaining the decision.
    `;
    const fullPrompt = `${moderationPrompt}\n\nPost Text: "${post.text}"\nSocial Platform: "${post.socialPlatform}"`;

    const requestParameters: GenerateContentParameters = {
      model: "gemini-2.5-pro",
      contents: [{ role: "user", parts: [{ text: fullPrompt }] }],
      config: {
        safetySettings: [
          {
            category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_HARASSMENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
          {
            category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
            threshold: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,
          },
        ],
      },
    };

    try {
      const response = await this.client.models.generateContent(requestParameters);

      // 1. First, check for a block from Gemini's built-in safety filters.
      const blockReason = response.promptFeedback?.blockReason;
      if (blockReason) {
        return {
          isApproved: false,
          reason: `Blocked by safety settings: ${blockReason}.`,
        };
      }

      // 2. If not blocked, extract the generated text.
      const generatedText = response.candidates?.[0]?.content?.parts?.[0]?.text;
      if (!generatedText) {
        return {
          isApproved: false,
          reason: "No content generated by the model.",
        };
      }
      const cleanedText = generatedText.replace(/```json|```/g, '').trim();

       // 3. Now, parse the JSON string from the generated text.
      let result: ModerationResult;
      try {
        const result: ModerationResult = JSON.parse(cleanedText);
        return result;
      } catch (parseError) {
        console.error("Failed to parse JSON response from model:", parseError);
        return {
          isApproved: false,
          reason: "Failed to parse model's moderation output as JSON.",
        };
      }
    } catch (err) {
      console.error("Gemini error", err);
      return {
        isApproved: false,
        reason: "Gemini moderation failed.",
      };
    }
  }
}
